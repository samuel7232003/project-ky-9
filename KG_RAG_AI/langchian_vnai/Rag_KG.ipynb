{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-28T16:21:44.300242Z",
     "start_time": "2025-10-28T16:20:47.579323Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 1,
   "source": [
    "import torch\n",
    "from transformers import BitsAndBytesConfig # Corrected import\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
   ],
   "id": "6d2f181007fb350f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T16:21:44.320457Z",
     "start_time": "2025-10-28T16:21:44.315166Z"
    }
   },
   "cell_type": "code",
   "source": "model_name:str = \"vilm/vinallama-7b-chat-GGUF\"",
   "id": "586b67be88c2f34f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T16:21:45.517003Z",
     "start_time": "2025-10-28T16:21:44.333915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# xây dựng hàm load LLM\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from transformers import BitsAndBytesConfig\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ],
   "id": "a55e59d4505a070",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T16:21:46.032731Z",
     "start_time": "2025-10-28T16:21:46.027179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_hf_llm(model_name=model_name, max_new_token=1024, **kwargs):\n",
    "  model = AutoModelForCausalLM.from_pretrained(\n",
    "      model_name,\n",
    "      quantization_config=nf4_config,\n",
    "      low_cpu_mem_usage=True\n",
    "  )\n",
    "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "  model_pipeline = pipeline(\n",
    "      \"text-generation\",\n",
    "      model=model,\n",
    "      tokenizer=tokenizer,\n",
    "      max_new_tokens=max_new_token,\n",
    "      pad_token_id=tokenizer.eos_token_id,\n",
    "      device_map=\"auto\"\n",
    "  )\n",
    "\n",
    "  llm = HuggingFacePipeline(\n",
    "      pipeline=model_pipeline,\n",
    "      model_kwargs=kwargs\n",
    "  )\n",
    "\n",
    "  return llm"
   ],
   "id": "de4244e39b8dc409",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T16:21:46.088403Z",
     "start_time": "2025-10-28T16:21:46.041478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# offline_rag.py\n",
    "import re\n",
    "\n",
    "from langchain_classic import hub\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "class Str_OutputParser(StrOutputParser):\n",
    "    def __init__(self) -> None:\n",
    "       super().__init__()\n",
    "\n",
    "    def parse(self, text: str) -> str:\n",
    "        return self.extract_answer(text)\n",
    "\n",
    "    def extract_answer(self,\n",
    "                       text_response: str,\n",
    "                       pattern: str = r\"Answer:\\s*(.*)\"\n",
    "                       ) -> str:\n",
    "\n",
    "        match = re.search(pattern, text_response, re.DOTALL)\n",
    "        if match:\n",
    "            answer_text = match.group(1).strip()\n",
    "            return answer_text\n",
    "        else:\n",
    "            return text_response\n",
    "\n",
    "class Offline_RAG:\n",
    "    def __init__(self, llm) -> None:\n",
    "        self.llm = llm\n",
    "        self.prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "        self.str_parser = Str_OutputParser()\n",
    "\n",
    "    def get_chain(self, retriever):\n",
    "        input_data = {\n",
    "            \"context\": retriever | self.format_docs,\n",
    "            \"question\": RunnablePassthrough()\n",
    "        }\n",
    "\n",
    "        rag_chain = (\n",
    "            input_data\n",
    "            | self.prompt\n",
    "            | self.llm\n",
    "            | self.str_parser\n",
    "        )\n",
    "\n",
    "        return rag_chain\n",
    "    def format_docs(self, docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ],
   "id": "ee05d240f9a7881b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2025-10-29T09:12:30.761570500Z",
     "start_time": "2025-10-29T09:08:37.600135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# vectorstore.py\n",
    "from typing import Union\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n",
    "class VectorDB:\n",
    "  def __init__(self,\n",
    "               documents = None,\n",
    "               vector_db: Union[Chroma, FAISS] = Chroma,\n",
    "               embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"),\n",
    "               ) -> None:\n",
    "    self.vector_db = vector_db\n",
    "    self.embedding = embedding\n",
    "    self.db = self._build_db(documents)\n",
    "\n",
    "  def _build_db(self, documents):\n",
    "    return self.vector_db.from_documents(\n",
    "                                        documents = documents,\n",
    "                                        embedding = self.embedding\n",
    "                                      )\n",
    "\n",
    "  def get_retriever(self,\n",
    "                    search_type: str = \"similarity\",\n",
    "                    search_kwargs: dict = {\"k\": 10}):\n",
    "    retriever = self.db.as_retriever(\n",
    "                                    search_type = search_type,\n",
    "                                    search_kwargs = search_kwargs\n",
    "                                  )\n",
    "    return retriever"
   ],
   "id": "9e01ff88a2869073",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "759eb2f4fa7746a1ab81efb968b62d3b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# file_loader\n",
    "from typing import Union, List, Literal\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def remove_non_utf8_characters(text):\n",
    "    return ''.join(char for char in text if ord(char) < 128)\n",
    "\n",
    "def load_pdf(pdf_file):\n",
    "  docs = PyPDFLoader(pdf_file, extract_images=True).load()\n",
    "  for doc in docs:\n",
    "    doc.page_content = remove_non_utf8_characters(doc.page_content)\n",
    "  return docs\n",
    "\n",
    "def get_num_cpu():\n",
    "  return multiprocessing.cpu_count()\n",
    "\n",
    "class BaseLoader:\n",
    "  def __init__(self) -> None:\n",
    "     self.num_processes = get_num_cpu()\n",
    "\n",
    "  def __call__(self, files: List[str], **kwargs):\n",
    "    pass\n",
    "\n",
    "class PDFLoader(BaseLoader):\n",
    "  def __init__(self) -> None:\n",
    "    super().__init__()\n",
    "\n",
    "  def __call__(self, pdf_file: List[str], **kwargs):\n",
    "    num_processes = min(self.num_processes, kwargs[\"workers\"] )\n",
    "    with multiprocessing.Pool(processes=num_processes) as pool:\n",
    "      doc_loaded = []\n",
    "      total_files = len(pdf_file)\n",
    "      with tqdm(total=total_files, desc=\"Loading PDFs\", unit=\"file\") as pbar:\n",
    "        for result in pool. imap_unordered(load_pdf, pdf_file):\n",
    "          doc_loaded.extend(result)\n",
    "          pbar.update(1)\n",
    "    return doc_loaded\n",
    "\n",
    "class TextSplitter:\n",
    "  def __init__(self,\n",
    "               separators: List[str] = [\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "               chunk_size: int = 300,\n",
    "               chunk_overlap: int = 0\n",
    "               ) -> None:\n",
    "    self.splitter = RecursiveCharacterTextSplitter(\n",
    "                                        separators = separators,\n",
    "                                        chunk_size = chunk_size,\n",
    "                                        chunk_overlap = chunk_overlap\n",
    "                                      )\n",
    "  def __call_(self, documents):\n",
    "    return self.splitter.split_documents(documents)\n",
    "\n",
    "class Loader:\n",
    "  def __init__(self,\n",
    "            file_type: str = Literal[\"pdf\"],\n",
    "            split_kwargs: dict = {\n",
    "            \"chunk_size\": 300,\n",
    "            \"chunk_overlap\": 0}\n",
    "            ) -> None:\n",
    "    assert file_type in [\"pdf\"], \"file_type must be pdf\"\n",
    "    self.file_type = file_type\n",
    "    if file_type == \"pdf\":\n",
    "      self.doc_loader = PDFLoader( )\n",
    "    else:\n",
    "      raise ValueError(\"file_type must be pdf\")\n",
    "\n",
    "    self.doc_spltter = TextSplitter( ** split_kwargs)\n",
    "\n",
    "  def load(self, pdf_files: Union[str, List[str]], workers: int = 1):\n",
    "    if isinstance(pdf_files, str):\n",
    "      pdf_files = [pdf_files]\n",
    "    doc_loaded = self.doc_loader(pdf_files, workers=workers)\n",
    "    doc_split = self.doc_spltter(doc_loaded)\n",
    "    return doc_split\n",
    "\n",
    "  def load_dir(self, dir_path: str, workers: int = 1):\n",
    "    if self.file_type == \"pdf\":\n",
    "      files = glob.glob(f\"{dir_path}/*. pdf\")\n",
    "      assert len(files) > 0, f\"No {self.file_type} files found in {dir_path}\"\n",
    "    else:\n",
    "      raise ValueError(\"file_type must be pdf\")\n",
    "    return self.load(files, workers=workers)"
   ],
   "id": "f1ec1c5d45d16c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# build rag source code: main.py\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class InputQA(BaseModel):\n",
    "  question: str = Field(..., title = \"Question to ask the model\")\n",
    "class OutputQA(BaseModel):\n",
    "  answer: str = Field(..., title = \"Answer from the model\")\n",
    "\n",
    "def build_rag_chain(llm, data_dir, data_type):\n",
    "  doc_loaded = Loader(file_type=data_type).load_dir(data_dir, workers=2)\n",
    "  retriever = VectorDB(documents = doc_loaded).get_retriever()\n",
    "  rag_chain = Offline_RAG(llm).get_chain(retriever)\n",
    "\n",
    "  return rag_chain"
   ],
   "id": "b91c8760cf8cadac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# chạy thử\n",
    "llm = get_hf_llm(temperature=0.9)\n",
    "genai_docs = \"/content/data_source/\"\n",
    "\n",
    "genai_chain = build_rag_chain(llm, genai_docs, \"pdf\")"
   ],
   "id": "e9bbb9a501b6b1dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "while True:\n",
    "  input = InputQA(question=input(\"Enter your question: \"))\n",
    "  answer = genai_chain.invoke(input.question)\n",
    "  print(answer)"
   ],
   "id": "f3543ec2f151172b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
