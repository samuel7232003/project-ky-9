{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T08:26:40.975871Z",
     "start_time": "2025-11-26T08:26:40.962147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import ast\n",
    "import re\n",
    "import csv"
   ],
   "id": "762f7beb92ae11d7",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T08:32:02.642781Z",
     "start_time": "2025-11-26T08:32:02.603760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------------------------------------------\n",
    "# 1. Tách các block JSON trong file TXT\n",
    "# ---------------------------------------------------------\n",
    "def extract_json_blocks(text: str):\n",
    "    \"\"\"\n",
    "    Tìm tất cả các block dạng:\n",
    "    ```json\n",
    "    [...]\n",
    "    ```\n",
    "    hoặc\n",
    "    ```python\n",
    "    [...]\n",
    "    ```\n",
    "    hoặc standalone {...}\n",
    "    \"\"\"\n",
    "    blocks = []\n",
    "\n",
    "    pattern = r\"```(?:json|python)?\\s*(.*?)```\"\n",
    "    matches = re.findall(pattern, text, flags=re.DOTALL)\n",
    "\n",
    "    for m in matches:\n",
    "        candidate = m.strip()\n",
    "        # Chỉ thêm block nếu có dấu [] hoặc {}\n",
    "        if (\"[\" in candidate and \"]\" in candidate) or (\"{\" in candidate and \"}\" in candidate):\n",
    "            blocks.append(candidate)\n",
    "\n",
    "    # Nếu KHÔNG tìm thấy block code → fallback: toàn bộ text có thể là JSON\n",
    "    if not blocks:\n",
    "        cleaned = text.strip()\n",
    "        if cleaned:\n",
    "            blocks = [cleaned]\n",
    "\n",
    "    return blocks\n",
    "\n"
   ],
   "id": "a3f2cd087f6a7854",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T08:32:05.383673Z",
     "start_time": "2025-11-26T08:32:05.372525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------------------------------------------\n",
    "# 2. Parse mỗi block thành list/dict Python\n",
    "# ---------------------------------------------------------\n",
    "def parse_block_to_python(block: str):\n",
    "    block = block.strip()\n",
    "\n",
    "    # Thử JSON trước\n",
    "    try:\n",
    "        return json.loads(block)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Thử ast.literal_eval (cho data dạng Python dict)\n",
    "    try:\n",
    "        return ast.literal_eval(block)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Thử trường hợp thiếu mảng ngoài\n",
    "    try:\n",
    "        wrapped = \"[\" + block + \"]\"\n",
    "        return json.loads(wrapped)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    print(block)\n",
    "\n",
    "    raise ValueError(\"Không parse được block:\\n\" + block[:200])"
   ],
   "id": "e6b0dc2169ca6a75",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T08:32:08.855783Z",
     "start_time": "2025-11-26T08:32:08.843170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------------------------------------------\n",
    "# 3. Chuẩn hóa một record (dict)\n",
    "# ---------------------------------------------------------\n",
    "def normalize_record(rec: dict):\n",
    "    def to_list(v):\n",
    "        if v is None:\n",
    "            return []\n",
    "        if isinstance(v, list):\n",
    "            return v\n",
    "        if isinstance(v, dict):\n",
    "            return [v]\n",
    "        return [v]\n",
    "\n",
    "    # Map key tiếng Việt → key tiếng Anh\n",
    "    mapping = {\n",
    "        \"Tên cây\": \"ten_cay\",\n",
    "        \"tên cây\": \"ten_cay\",\n",
    "        \"Loại bệnh\": \"loai_benh\",\n",
    "        \"loại bệnh\": \"loai_benh\",\n",
    "        \"Nguyên nhân\": \"nguyen_nhan\",\n",
    "        \"nguyên nhân\": \"nguyen_nhan\",\n",
    "        \"Triệu chứng\": \"trieu_chung\",\n",
    "        \"triệu chứng\": \"trieu_chung\",\n",
    "        \"Cách điều trị\": \"cach_dieu_tri\",\n",
    "        \"cách điều trị\": \"cach_dieu_tri\",\n",
    "    }\n",
    "\n",
    "    out = {\n",
    "        \"ten_cay\": \"\",\n",
    "        \"loai_benh\": \"\",\n",
    "        \"nguyen_nhan\": [],\n",
    "        \"trieu_chung\": [],\n",
    "        \"cach_dieu_tri\": []\n",
    "    }\n",
    "\n",
    "    for k, v in rec.items():\n",
    "        if k in mapping:\n",
    "            mk = mapping[k]\n",
    "            if mk in [\"ten_cay\", \"loai_benh\"]:\n",
    "                out[mk] = v.strip() if isinstance(v, str) else str(v)\n",
    "            else:\n",
    "                out[mk] = to_list(v)\n",
    "            # out[mk] = to_list(v)\n",
    "        else:\n",
    "            # key không map → bỏ qua\n",
    "            pass\n",
    "\n",
    "    return out"
   ],
   "id": "6928bd3b1d52bf4b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T08:32:14.926971Z",
     "start_time": "2025-11-26T08:32:14.898856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------------------------------------------\n",
    "# 4. Tạo pipeline TXT → JSON → CSV\n",
    "# ---------------------------------------------------------\n",
    "def pipeline(txt_path: str, json_path: str, csv_path: str):\n",
    "    # Đọc file\n",
    "    with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        raw = f.read()\n",
    "\n",
    "    # Tách block JSON-like\n",
    "    blocks = extract_json_blocks(raw)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for block in blocks:\n",
    "        if block.startswith(\"Dưới đây\") or block.startswith(\"Dựa trên nội dung\") or block.startswith(\"Từ nội dung\") or block.startswith(\"Dựa vào nội dung\"):\n",
    "            print(block)\n",
    "            continue\n",
    "        print(\"---------------\")\n",
    "        parsed = parse_block_to_python(block)\n",
    "        # Trường hợp block là list\n",
    "        if isinstance(parsed, list):\n",
    "            for item in parsed:\n",
    "                if isinstance(item, dict):\n",
    "                    results.append(normalize_record(item))\n",
    "        # Trường hợp block là dict\n",
    "        elif isinstance(parsed, dict):\n",
    "            results.append(normalize_record(parsed))\n",
    "    # Ghi CSV\n",
    "    with open(csv_path, \"a\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(\n",
    "            f,\n",
    "            fieldnames=[\"ten_cay\", \"loai_benh\", \"nguyen_nhan\", \"trieu_chung\", \"cach_dieu_tri\"]\n",
    "        )\n",
    "        writer.writeheader()\n",
    "        for r in results:\n",
    "            writer.writerow({\n",
    "                \"ten_cay\": r[\"ten_cay\"],\n",
    "                \"loai_benh\": r[\"loai_benh\"],\n",
    "                \"nguyen_nhan\": \" | \".join(map(str, r[\"nguyen_nhan\"])),\n",
    "                \"trieu_chung\": \" | \".join(map(str, r[\"trieu_chung\"])),\n",
    "                \"cach_dieu_tri\": \" | \".join(map(str, r[\"cach_dieu_tri\"])),\n",
    "            })\n",
    "\n",
    "    print(f\"✔ Hoàn thành! Tổng số record: {len(results)}\")\n",
    "    print(f\"→ JSON: {json_path}\")\n",
    "    print(f\"→ CSV:  {csv_path}\")"
   ],
   "id": "819cee11aa0e312f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T08:40:42.276465Z",
     "start_time": "2025-11-26T08:40:42.000543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pipeline(\n",
    "        txt_path=\"raw_data/raw_data_general_2.txt\",\n",
    "        json_path=\"clean_data_test1.json\",\n",
    "        csv_path=\"data/general_data_raw_3.csv\"\n",
    "    )\n"
   ],
   "id": "b9a5b648d045cf0e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "✔ Hoàn thành! Tổng số record: 541\n",
      "→ JSON: clean_data_test1.json\n",
      "→ CSV:  data/general_data_raw_3.csv\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
